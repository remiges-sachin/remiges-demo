version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: demo-postgres
    environment:
      POSTGRES_USER: remiges
      POSTGRES_PASSWORD: remiges123
      POSTGRES_DB: userdb
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./pg/migrations/000001_create_users_table.up.sql:/docker-entrypoint-initdb.d/001_create_users.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U remiges -d userdb"]
      interval: 10s
      timeout: 5s
      retries: 5

  etcd:
    image: quay.io/coreos/etcd:v3.5.9
    container_name: demo-etcd
    command:
      - /usr/local/bin/etcd
      - --name=etcd0
      - --data-dir=/etcd-data
      - --advertise-client-urls=http://etcd:2379
      - --listen-client-urls=http://0.0.0.0:2379
      - --initial-advertise-peer-urls=http://etcd:2380
      - --listen-peer-urls=http://0.0.0.0:2380
      - --initial-cluster=etcd0=http://etcd:2380
    ports:
      - "2379:2379"
      - "2380:2380"
    volumes:
      - etcd_data:/etcd-data

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: demo-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: demo-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    container_name: demo-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana for ElasticSearch visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.2
    container_name: demo-kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
      ELASTICSEARCH_USERNAME: "kibana_system"
      ELASTICSEARCH_PASSWORD: "kibana"
      SERVER_NAME: "demo-kibana"
      SERVER_HOST: "0.0.0.0"
      XPACK_SECURITY_ENABLED: "false"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Optional: Kafka UI for monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: demo-kafka-ui
    depends_on:
      - kafka
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  # LogHarbour Consumer - consumes from Kafka and indexes to Elasticsearch
  logharbour-consumer:
    build:
      context: ./logharbour
      dockerfile: Dockerfile
    container_name: demo-logharbour-consumer
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_ADDRESSES: "http://elasticsearch:9200"
      KAFKA_BROKERS: "kafka:29092"
      KAFKA_TOPIC: "logharbour-logs"
      ELASTICSEARCH_INDEX: "logharbour"
      KAFKA_BATCH_SIZE: "10"
      USE_CONSUMER_GROUP: "true"
      KAFKA_CONSUMER_GROUP: "logharbour-consumer-group"
      KAFKA_OFFSET_TYPE: "earliest"
      LOG_LEVEL: "info"
    networks:
      - default
    restart: unless-stopped

volumes:
  postgres_data:
  etcd_data:
  elasticsearch_data: